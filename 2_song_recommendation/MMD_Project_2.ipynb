{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import zipfile as zf\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify file name / location here:\n",
    "file_name = 'train_triplets.txt'\n",
    "zip_location = './train_triplets.txt.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AVERAGE_LINE_SIZE = 63  # average number of bytes in a line, tells readlines() how far to read the file\n",
    "\n",
    "class RecommenderSystem:\n",
    "    def __init__(self, alpha=3, bins=10, codec='utf-8', file_name='train_triplets.txt', num_factors_k=30,\n",
    "                 n_triplets=300000, optimization_steps=10, zip_location='./train_triplets.txt.zip'):\n",
    "        \"\"\"\n",
    "        Initialization of a recommender system\n",
    "        :param alpha:               alpha penalty of the ridge regression model (default is 3)\n",
    "        :param bins:                how many logarithmic bins to split the play counts into (default is 10)\n",
    "        :param codec:               character encoding of the .txt file\n",
    "        :param file_name:           name of the .txt file\n",
    "        :param num_factors_k:       how many latent factors to compute (default is 30)\n",
    "        :param n_triplets:          how many triplets from the .txt file to consider (default is 300000)\n",
    "        :param optimization_steps:  how many times to alternatingly optimize P and Q\n",
    "        :param zip_location:        the location of the .zip file\n",
    "        \"\"\"\n",
    "        # initialization values\n",
    "        self.alpha = alpha\n",
    "        self.bins = bins\n",
    "        self.codec = codec\n",
    "        self.file_name = file_name\n",
    "        self.num_factors_k = num_factors_k\n",
    "        self.n_triplets = n_triplets\n",
    "        self.optimization_steps = optimization_steps\n",
    "        self.zip_location = zip_location\n",
    "\n",
    "        # create self.matrix_R_df\n",
    "        self.R = self.get_matrix()\n",
    "        self.n = self.R.shape[0]\n",
    "        self.d = self.R.shape[1]\n",
    "        # set aside 200 values from the matrix to validate\n",
    "        self.validation = self.extract_validation_data()\n",
    "        # initialize P and Q using SVD\n",
    "        self.P, self.Q = self.initialize_P_Q()\n",
    "\n",
    "    def get_matrix(self):\n",
    "        # unzip the file as far as necessary\n",
    "        zfile = zf.ZipFile(self.zip_location)\n",
    "        ifile = zfile.open(self.file_name)\n",
    "        line_list = ifile.readlines(self.n_triplets * AVERAGE_LINE_SIZE)\n",
    "        # write each entry of the triplets to their own list\n",
    "        users = []\n",
    "        songs = []\n",
    "        counts = []\n",
    "        for l in range(self.n_triplets):\n",
    "            user, song, count = line_list[l].decode(self.codec).strip('\\n').split('\\t')\n",
    "            users.append(user)\n",
    "            songs.append(song)\n",
    "            counts.append(count)\n",
    "        # convert the IDs from ugly 40 byte strings to consecutive integers\n",
    "        userlist, userids = np.unique(np.asarray(users), return_inverse=True)   # np.unique is getting to be my favorite\n",
    "        songlist, songids = np.unique(np.asarray(songs), return_inverse=True)   # function after 2 projects in this class ;)\n",
    "        # bin the play counts\n",
    "        binned_counts = np.minimum(np.asarray(np.log2(np.asarray(counts, dtype='uint64') * 2), dtype='uint64'), self.bins)\n",
    "        # create the matrix\n",
    "        R = sp.coo_matrix((binned_counts, (songids, userids))).tocsr()\n",
    "        # recursively remove rows/columns with <=5 entries\n",
    "        for i in range(10):     # just to make sure this doesn't run forever, 10 should be more than enough\n",
    "            r_entries = R.tocsc()\n",
    "            r_entries.data = np.ones(r_entries.data.shape)\n",
    "            entries_per_row = np.asarray(r_entries.sum(1)).flatten()\n",
    "            R = R[entries_per_row > 5]\n",
    "            r_entries = R.tocsc()\n",
    "            r_entries.data = np.ones(r_entries.data.shape)\n",
    "            entries_per_column = np.asarray(r_entries.sum(0)).flatten()\n",
    "            if np.min(entries_per_column) > 5 and np.min(entries_per_row) > 5:\n",
    "                break\n",
    "            R = R[:, entries_per_column > 5]\n",
    "        return R\n",
    "\n",
    "    def extract_validation_data(self):\n",
    "        validation = np.zeros([200, 3], dtype='uint32')\n",
    "        index = np.vstack(np.nonzero(self.R)).T\n",
    "        shuff = np.random.permutation(index)\n",
    "        for i, (x, y) in enumerate(shuff[:200]):\n",
    "            validation[i] = [x, y, self.R[x, y]]\n",
    "            self.R[x, y] = 0\n",
    "        return validation\n",
    "\n",
    "    def initialize_P_Q(self):\n",
    "        U, S, Pt = sp.linalg.svds(self.R.asfptype(), k=self.num_factors_k)   # requires casting to float for some reason\n",
    "        Q = U.dot(np.diag(S))\n",
    "        P = Pt.T\n",
    "        return P, Q\n",
    "\n",
    "    def find_latent_factors(self, optimization_steps=None):\n",
    "        # n: how many items/songs we have\n",
    "        # d: how many users we have\n",
    "        # Given:                Matrix R (n x d)\n",
    "        # Find latent factors:  Matrix Q (n x k) and P (d x k) to minimize error for R = Q * P.T (=> P.T is k x d!)\n",
    "        # Using alternating optimization\n",
    "        if not optimization_steps:\n",
    "            optimization_steps = self.optimization_steps\n",
    "        self.reg = linear_model.Ridge(alpha=self.alpha, fit_intercept=False)\n",
    "        error = np.sum(np.square(self.R[self.R.nonzero()] - self.Q.dot(self.P.transpose())[self.R.nonzero()]))\n",
    "        print('initial error =', error)\n",
    "        for i in range(optimization_steps):     # alternatingly optimize for 20 steps (no idea how much is good)\n",
    "            self.compute_P()\n",
    "            self.compute_Q()\n",
    "            error = np.sum(np.square(self.R[self.R.nonzero()] - self.Q.dot(self.P.transpose())[self.R.nonzero()]))\n",
    "            print('error after {} steps = {}'.format(i + 1, error))\n",
    "\n",
    "    def compute_P(self):\n",
    "        for d in range(self.d):                         # looping over users d to compute rows of P\n",
    "            y_nonsparse = self.R.getcol(d)              # get the d'th column of items from R\n",
    "            indices = y_nonsparse.nonzero()[0]\n",
    "            # only select the songs in that column that user d has listened to:\n",
    "            y = np.asarray(y_nonsparse[y_nonsparse.nonzero()]).flatten()\n",
    "            X = self.Q[indices]                         # only select the corresponding rows from Q\n",
    "            self.reg.fit(X, y)                          # perform ridge regression for this selection\n",
    "            self.P[d] = self.reg.coef_                  # write this result to the d'th row of P\n",
    "\n",
    "    def compute_Q(self):\n",
    "        for n in range(self.n):                         # looping over songs n to compute rows of Q\n",
    "            y_nonsparse = self.R.getrow(n)              # get the n'th row of users from R\n",
    "            indices = y_nonsparse.nonzero()[1]\n",
    "            # only select the users in that row that have listened to song n:\n",
    "            y = np.asarray(y_nonsparse[y_nonsparse.nonzero()]).flatten()\n",
    "            X = self.P[indices]                         # only select the corresponding rows from P\n",
    "            self.reg.fit(X, y)                          # perform ridge regression for this selection\n",
    "            self.Q[n] = self.reg.coef_                  # write this result to the n'th row of Q\n",
    "\n",
    "    def evaluate(self):\n",
    "        errors = [(val[2] - self.make_prediction(val[0], val[1]))**2 for val in self.validation]\n",
    "        rmse = (sum(errors)/len(errors))**0.5\n",
    "        print('mean squared error with {} latent factors: RMSE = {}'.format(self.num_factors_k, rmse))\n",
    "\n",
    "    def make_prediction(self, song, user):\n",
    "        return np.dot(self.Q[song], self.P[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error with 30 latent factors: RMSE = 2.072805582136889\n"
     ]
    }
   ],
   "source": [
    "# create recommender (feel free to add more parameters here)\n",
    "recommender = RecommenderSystem(file_name=file_name, zip_location=zip_location)\n",
    "\n",
    "# see how good it performs purely from the SVD initialization:\n",
    "recommender.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error = 410480.560154\n",
      "error after 1 steps = 83041.55338935749\n",
      "error after 2 steps = 34398.363920314994\n",
      "error after 3 steps = 29331.584887217585\n",
      "error after 4 steps = 27292.09403787067\n",
      "error after 5 steps = 26185.971140385853\n",
      "error after 6 steps = 25484.793342798846\n",
      "error after 7 steps = 24997.135832830332\n",
      "error after 8 steps = 24636.942010378832\n",
      "error after 9 steps = 24359.78522714035\n",
      "error after 10 steps = 24140.25791580917\n",
      "Finding latent factors takes 190.22467613220215sec\n"
     ]
    }
   ],
   "source": [
    "# alternatingly optimize latent factors (this takes about 5 minutes for k=30)\n",
    "t_start = time.time()\n",
    "recommender.find_latent_factors(optimization_steps=10)\n",
    "t_finish = time.time()\n",
    "print('Finding latent factors takes {}sec'.format(t_finish - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error with 30 latent factors: RMSE = 1.1619595817113526\n"
     ]
    }
   ],
   "source": [
    "# check how much the optimization improved things\n",
    "recommender.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes our RMSE from 2.07 to 1.16. \n",
    "Further optimization might improve the RMSE, however the time cost of the optimization is quite high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
