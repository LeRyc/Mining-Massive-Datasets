{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Project Task 3 - Song Ranker****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/yames/Robotics/MMD/project/lastfm_subset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RankingSystem:\n",
    "    def __init__(self, path='./lastfm_train/', t_threshold=0.0, g_threshold=50, n_songs=5, beta=0.2):\n",
    "        \"\"\"\n",
    "        :param path:        location of the folder containing all the last.fm json files\n",
    "        :param t_threshold: minimum similarity required for two songs to be considered adjacent\n",
    "        :param g_threshold: minimum count required for a tag to be included\n",
    "        :param n_songs:     number of best matches to return to user\n",
    "        :param n_songs:     teleport probability\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.g_threshold = g_threshold\n",
    "        self.t_threshold = t_threshold\n",
    "        self.n_songs = n_songs\n",
    "        self.beta = beta\n",
    "        self.info_dict = {}\n",
    "        self.adjacency_matrix, self.matrix_keys, self.tag_matrix, self.tag_names = self.load_json_data()\n",
    "        self.N = len(self.matrix_keys)\n",
    "        degrees = self.adjacency_matrix.sum(axis=0).A1\n",
    "        self.dead_ends = (degrees == 0).astype(np.int)\n",
    "        self.stochastic_adjacency = normalize(self.adjacency_matrix, norm='l1', axis=0)\n",
    "\n",
    "    def load_json_data(self):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # start with a smallish array, grow dynamically\n",
    "        edges = np.empty([765, 2], dtype='<U18')\n",
    "        tags = np.empty([543, 2], dtype='<U18')\n",
    "\n",
    "        # count how big the array needs to be\n",
    "        edge_index = 0\n",
    "        tag_index = 0\n",
    "\n",
    "        # dirwalk over all json files\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for name in files:\n",
    "                if name.endswith(\".json\"):\n",
    "                    # who the ???? is jason?\n",
    "                    jason = json.load(open(root + '/' + name))\n",
    "                    self.info_dict[jason['track_id']] = jason['artist'] + ' - ' + jason['title']\n",
    "\n",
    "                    # read tags\n",
    "                    this_song_tags = np.asarray(jason['tags'], dtype='<U18')\n",
    "                    num_tags = len(this_song_tags)\n",
    "                    if num_tags:\n",
    "                        this_song_tag_counts = this_song_tags[:, 1].astype(np.int)\n",
    "                        this_song_tags[:, 1] = jason['track_id']  # second column contains the trackID having the tag\n",
    "                        tags_above_threshold = this_song_tags[this_song_tag_counts > self.g_threshold]\n",
    "                        num_tags = len(tags_above_threshold)\n",
    "                        if tag_index + num_tags > len(tags):  # dynamically grow array\n",
    "                            tags = np.vstack([tags, np.empty_like(tags)])\n",
    "                        tags[tag_index: tag_index + num_tags] = tags_above_threshold\n",
    "                        tag_index += num_tags\n",
    "\n",
    "                    # read similar songs\n",
    "                    this_song_edges = np.asarray(jason['similars'])\n",
    "                    num_edges = len(this_song_edges)\n",
    "                    if num_edges:  # ignore files that have no similars listed\n",
    "                        this_song_edge_weights = this_song_edges[:, 1].astype(np.float)\n",
    "                        this_song_edges[:, 1] = jason['track_id']  # second column contains the trackID the edge leaves\n",
    "                        edges_above_threshold = this_song_edges[this_song_edge_weights > self.t_threshold]\n",
    "                        num_edges = len(edges_above_threshold)\n",
    "                        if edge_index + num_edges > len(edges):  # dynamically grow array\n",
    "                            edges = np.vstack([edges, np.empty_like(edges)])\n",
    "                        edges[edge_index: edge_index + num_edges] = edges_above_threshold\n",
    "                        edge_index += num_edges\n",
    "\n",
    "        # reduce array size back to the amount necessary\n",
    "        edges = edges[:edge_index]\n",
    "        tags = tags[:tag_index]\n",
    "        print('''All json files read after {} seconds. Found {} edges and {} tags. \n",
    "        Populating sparse matrices...'''.format(time.time()-t0, len(edges), len(tags)))\n",
    "\n",
    "        # we don't want 18 character strings as identifiers, integers are much easier to work with\n",
    "        array_containing_all_trackids = np.hstack([edges.reshape(-1), tags[:, 1]])\n",
    "        tag_strings, tag_integers = np.unique(tags[:, 0], return_inverse=True)\n",
    "        del tags\n",
    "        del edges\n",
    "        trackids, array_of_track_integers = np.unique(array_containing_all_trackids, return_inverse=True)\n",
    "        del array_containing_all_trackids\n",
    "        in_nodes = array_of_track_integers[:edge_index]\n",
    "        out_nodes = array_of_track_integers[edge_index:2*edge_index]\n",
    "        integer_tag_owners = array_of_track_integers[2*edge_index:]\n",
    "\n",
    "        # create sparse matrices\n",
    "        adjacency_matrix = csc_matrix((np.ones(len(out_nodes)), (out_nodes, in_nodes)), shape=[len(trackids)] * 2)\n",
    "        tag_matrix = csc_matrix((np.ones(len(tag_integers)), (integer_tag_owners, tag_integers)),\n",
    "                                shape=[len(trackids), len(tag_strings)])\n",
    "\n",
    "        print('Parsed json files and created matrices in {} seconds'.format(time.time()-t0))\n",
    "        return adjacency_matrix, trackids, tag_matrix, tag_strings\n",
    "\n",
    "    def get_all_tags(self):\n",
    "        return self.tag_names\n",
    "\n",
    "    def compute_page_rank_vector(self, epsilon=0.0000001, beta=None, S=None):\n",
    "        \"\"\"\n",
    "        :param beta:    probability to teleport\n",
    "        :param S:       vector of songs to teleport to (higher values means higher teleport likelihood)\n",
    "        :param epsilon: convergence error\n",
    "        :return:        page rank vector\n",
    "        \"\"\"\n",
    "        if S is None:\n",
    "            S = np.ones(self.N)\n",
    "        if beta is None:\n",
    "            beta = self.beta\n",
    "        initial_y = np.random.rand(self.N)  # initial_y = np.ones(N)\n",
    "        initial_y /= np.sum(initial_y)\n",
    "\n",
    "        # this added factor means that information doesn't get lost in dead ends, but instead teleports out:\n",
    "        dead_end_escaper = self.dead_ends.dot(initial_y)\n",
    "        y = self.stochastic_adjacency.dot(initial_y) * (1 - beta) + (S / np.sum(S)) * (beta + dead_end_escaper)\n",
    "\n",
    "        i = 0   # just so we don't loop too often if it doesn't converge\n",
    "        while np.linalg.norm(y - initial_y) > epsilon and i < 100:\n",
    "            i += 1\n",
    "            initial_y = y\n",
    "            dead_end_escaper = self.dead_ends.dot(initial_y)\n",
    "            y = self.stochastic_adjacency.dot(initial_y) * (1 - beta) + (S / np.sum(S)) * (beta + dead_end_escaper)\n",
    "        return y\n",
    "\n",
    "    def topic_specific_page_rank(self, tags=(), n_songs=None, beta=None):\n",
    "        \"\"\"\n",
    "        :param beta:    probability of teleport\n",
    "        :param tags:    tags to include for the topic specifc page rank, as list of strings.\n",
    "        :param n_songs: override global default for number of songs to return\n",
    "        :return:        top n ranked tracks from the given page rank\n",
    "        \"\"\"\n",
    "        if n_songs is None:\n",
    "            n_songs = self.n_songs\n",
    "        if beta is None:\n",
    "            beta = self.beta\n",
    "        feature_strings = []\n",
    "        S = np.zeros(self.N)\n",
    "        for tag in tags:\n",
    "            bla = np.argwhere(self.tag_names == tag).flatten()\n",
    "            if len(bla):\n",
    "                feature_strings.append(tag)\n",
    "                S += np.asarray(self.tag_matrix.getcol(bla[0]).todense()).flatten()\n",
    "        if len(feature_strings) == 0:\n",
    "            print('No valid tags provided, computing ranking on global data set instead.')\n",
    "            S = None\n",
    "        else:\n",
    "            print('Using features', feature_strings, 'with teleport subset size:', np.sum(S), '/', len(S))\n",
    "        rank_vector = self.compute_page_rank_vector(beta=beta, S=S)\n",
    "        return [self.info_dict.get(tid, tid+' - Unknown Track') for tid in self.matrix_keys[np.argsort(rank_vector)[:-(n_songs + 1):-1]]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Ranking System\n",
    "\n",
    "This may take a while to parse all the json files, as there are quite a few of them. For us it's approximately 20 minutes for the entire training set (2.5gb of json). However once this is done, one can easily compute many page rank queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All json files read after 9.939356088638306 seconds. Found 612051 edges and 11773 tags. \n",
      "        Populating sparse matrices...\n",
      "Parsed json files and created matrices in 11.102881908416748 seconds\n"
     ]
    }
   ],
   "source": [
    "ranking = RankingSystem(path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Tags\n",
    "\n",
    "there's quite a few junk tags even after sorting out, but one can look up the tags that are possible to pass to the page rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total there are 3749 tags. They are:\n",
      "['---04fh' '--7' '--8' ..., 'zuidelijk' 'zydeco' 'zz96jd']\n"
     ]
    }
   ],
   "source": [
    "tags = ranking.get_all_tags()\n",
    "print('In total there are', len(tags), 'tags. They are:')\n",
    "print(tags)\n",
    "# # Uncomment this if you want a wall of text:\n",
    "# for tag in tags:\n",
    "#     print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Specific Page Rank\n",
    "\n",
    "It would perhaps be possible to play around with upper/lower case variants to see how it affects results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features ['hip hop', 'rap'] with teleport subset size: 183.0 / 203970\n",
      "['Dilated Peoples - Hard Hitters', 'Mobb Deep - Hell On Earth (Front Lines)', 'JAY-Z - Change Clothes', 'LL Cool J - Headsprung', 'Busta Rhymes - Genesis', 'The Game - Scream On Em', 'Dendemann - Sachmagehtsnoch', 'Common - The 6th Sense', \"The Beatnuts - No Escapin' This\", \"The Pharcyde - Passin' Me By\"]\n"
     ]
    }
   ],
   "source": [
    "best_songs = ranking.topic_specific_page_rank(beta=0.2, tags=('hip hop', 'rap'),  n_songs=10)\n",
    "print(best_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features ['rock', 'metal', 'folk metal'] with teleport subset size: 643.0 / 203970\n",
      "['System of a Down - Streamline', 'Helmet - Street Crab', 'Becoming the Archetype - Ex Nihilo', 'Y&T - Mean Streak', 'Helmet - Give It']\n"
     ]
    }
   ],
   "source": [
    "best_songs = ranking.topic_specific_page_rank(beta=0.4, tags=('rock', 'metal', 'power-metal', 'folk metal'))\n",
    "print(best_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
